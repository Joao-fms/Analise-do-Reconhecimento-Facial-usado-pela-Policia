# ğŸ“š Reconhecimento Facial pela PolÃ­cia: SeguranÃ§a ou ViolaÃ§Ã£o de Direitos
### ğŸ“– Sobre o Projeto

Este repositÃ³rio contÃ©m um estudo crÃ­tico sobre o uso da tecnologia de reconhecimento facial pela polÃ­cia, analisando seus impactos sociais, Ã©ticos e jurÃ­dicos.
O trabalho discute se a adoÃ§Ã£o dessa tecnologia representa um avanÃ§o para a seguranÃ§a pÃºblica ou uma ameaÃ§a aos direitos fundamentais.

### ğŸ‘¥ Autores

JoÃ£o Fernando Moraes Dos Santos â€“ RGM: 45654841

Felipe Nogueira Santos â€“ RGM: 45043922

ClÃ©vio Welber Dias Gomes â€“ RGM: 45142581

### ğŸ“ Pontos de DiscussÃ£o

#### O estudo foi estruturado a partir de quatro grandes eixos:

ViÃ©s e JustiÃ§a: impactos discriminatÃ³rios contra minorias (homens negros, indÃ­genas, mulheres).

TransparÃªncia e Explicabilidade: limitaÃ§Ã£o dos modelos de IA por serem â€œcaixas-pretasâ€.

Impacto Social e Direitos: ameaÃ§as Ã  privacidade, liberdade e nÃ£o discriminaÃ§Ã£o.

Responsabilidade e GovernanÃ§a: ausÃªncia de regulamentaÃ§Ã£o clara e necessidade de â€œAI Ethics by Designâ€.

### âš–ï¸ Principais ConclusÃµes

âŒ ViÃ©s e InjustiÃ§a: a tecnologia atinge desproporcionalmente grupos minoritÃ¡rios, causando falsas identificaÃ§Ãµes.

âŒ Falta de TransparÃªncia: decisÃµes algorÃ­tmicas sÃ£o opacas e nÃ£o explicÃ¡veis.

âŒ ViolaÃ§Ã£o de Direitos: riscos Ã  privacidade e Ã  liberdade individual, contrariando legislaÃ§Ãµes como a LGPD.

âŒ GovernanÃ§a Ausente: inexistÃªncia de regulamentaÃ§Ã£o robusta e eficaz.

### âœ… Propostas de SoluÃ§Ã£o

Desenvolvimento Ã‰tico: uso de bases de dados diversas e testes rigorosos.

TransparÃªncia e Auditoria: criaÃ§Ã£o de modelos explicÃ¡veis, com decisÃµes finais supervisionadas por humanos.

RegulamentaÃ§Ã£o Rigorosa: leis especÃ­ficas para limitar abusos e proteger os cidadÃ£os.


### ğŸ“Œ LicenÃ§a

#### Este projeto Ã© apenas acadÃªmico e nÃ£o possui fins comerciais.
